[
["introduction.html", "Baysian Linear Models in the Property Markets 1 Introduction 1.1 Why use Bayesian?", " Baysian Linear Models in the Property Markets James Murray June 2020 1 Introduction All Models are wrong, but some are useful George Box - 1976 There will be more than 700 000 homes created in the greater Sydney Region between now and 2036 as part of the Greater Sydney Commission’s Strategic Plan. The effects this will have on property prices is as yet unknown but must be measured carefully in an effort to preserve, or improve, the lending ratio’s in a highly leveraged market place. The factors that affect property prices are many and varied. Based on developed linear models the results offered that access to services and business districts are considered principle aspects among the influences and this should be a key consideration when developing the strategic plan for the Greater Sydney Region. As such, to further refine this idea the following question will be answered What is the probability that access to services and business districts will affect property prices? From these measures of the linear model that the group created we can see that it is still only possible to predict the house price to within $340 000. This is a considerable amount of money in real terms in a highly leveraged market place. The estimated value from the original model is 1.22mil across the Sydney Region. These metrics will be used to assess the existing model against the newly generated Bayesian model. 1.1 Why use Bayesian? In order to answer this highlights from both frequentist and Bayesian methods are offered below. Frequentists Frequentist statistical approaches are based on the following ideas (Bolstad 2017) They assume that numerical characteristics of the population are fixed but unknown. Probabilities are always interpreted as a long-run relative frequency, and The performance of statistical procedures is considered over long-run infinite hypothetical repetitions. Baysian On the other hand, Bayesian concepts offer a way to consistently update our beliefs about the parameters given the Data that actually occurred (Bolstad 2017). The essence of this concept is the way the variables are considered. By allowing parameters to be considered as random variables it allows probability statements to be made about the variables themselves based on what the belief is at that point in time and space - it allows us to allocate credibility across the possibilities associated within the observed system. Bayesian inference allows us to compute the exact relative credibilities of candidate parameter values, while also taking into account their prior probabilities (Kruschke 2015). In formula terms we can write Bayes Theorem as: \\(P(A|B)=\\frac{P(B|A)*P(A)}{P(B)}\\qquad\\) which means Posterior = \\(\\frac{\\mbox{Likelihood} * \\mbox{Prior}}{\\mbox{Marginal}}\\) This can be rewritten as an inference model below: \\(P(\\theta|D)=\\frac{P(D|\\theta)*P(\\theta)}{P(D)}\\qquad\\) In the theorm above the weighting of the posterior against the prior changes as the amount of Data obtained increases when compared with the number of variables being considered. This will be apparent in the model generated when considering property prices. Critically, the method of measuring the confidence intervals(CI) between the two approaches is the way this is set apart. CIs under the Frequentist approach are not interpretable in terms of post-data probabilities where as the Bayesian uncertainty interval is set following analysis of the data. This allows confidence intervals to move as the model learns from the Data - as new information comes to light then the model is updated providing new uncertainty intervals. Biblography "],
["data-preparation-and-modelling.html", "2 Data Preparation and Modelling 2.1 Data Preparation 2.2 Modelling 2.3 Model Selection", " 2 Data Preparation and Modelling To determine likelihood of property price response around access to services and business districts the Data modelling was limited to distance from CBD and access to services (schools and train stations). The summary statistics and results for the adjusted linear model are at Annex 1 2.1 Data Preparation The Data set used for this modelling is the same Data that was used for the original linear model with outliers removed. This offered a Data set of more than 47 000 observations. This was further broken into a training and testing Data set with a ratio of 80/20. 2.2 Modelling The model used was a Bayesian Generalized Linear model using Markov Chain Monte Carlo (MCMC) to develop the inference. The method for modelling and model selection was to incorporate the different levels of priors as part of the model selection process then assess the model. Three different kinds of priors were used to select the model: Flat Priors Weakly Informative Priors, and Informative Priors The selection and details around these priors was taken from the initial linear regression modelling completed. These results can be found at Annex 1. Firstly we will address the Flat Priors. The default priors in rstanarm are designed to be weakly informative. This means that the priors have to be set to NULL in rstanarm to get flat priors. It is seldom useful to use flat priors unless there is a requirement to refer to the parameterization-invariant Jefferys prior. The Flat Priors model results are below. ## ## Model Info: ## function: stan_glm ## family: gaussian [identity] ## formula: price ~ distance_from_CBD + distance_from_closest_private_school + ## distance_from_closest_station + distance_from_closest_public_school ## algorithm: sampling ## sample: 4000 (posterior sample size) ## priors: see help(&#39;prior_summary&#39;) ## observations: 38394 ## predictors: 5 ## ## Estimates: ## mean sd 10% 50% ## (Intercept) 1227592.4 3803.1 1222823.4 1227640.6 ## distance_from_CBD -9839.0 81.1 -9939.7 -9839.8 ## distance_from_closest_private_school -5671.3 1631.4 -7769.1 -5684.0 ## distance_from_closest_station 16542.3 638.4 15710.1 16556.1 ## distance_from_closest_public_school 58871.0 3869.9 53866.3 58839.3 ## sigma 340969.6 1215.6 339377.4 340978.6 ## 90% ## (Intercept) 1232436.8 ## distance_from_CBD -9735.0 ## distance_from_closest_private_school -3548.8 ## distance_from_closest_station 17342.9 ## distance_from_closest_public_school 63807.6 ## sigma 342539.3 ## ## Fit Diagnostics: ## mean sd 10% 50% 90% ## mean_PPD 939676.3 2475.2 936512.7 939652.5 942855.1 ## ## The mean_ppd is the sample average posterior predictive distribution of the outcome variable (for details see help(&#39;summary.stanreg&#39;)). ## ## MCMC diagnostics ## mcse Rhat n_eff ## (Intercept) 51.9 1.0 5360 ## distance_from_CBD 1.3 1.0 4202 ## distance_from_closest_private_school 28.7 1.0 3234 ## distance_from_closest_station 9.8 1.0 4256 ## distance_from_closest_public_school 60.9 1.0 4041 ## sigma 13.8 1.0 7738 ## mean_PPD 38.7 1.0 4092 ## log-posterior 0.0 1.0 1771 ## ## For each parameter, mcse is Monte Carlo standard error, n_eff is a crude measure of effective sample size, and Rhat is the potential scale reduction factor on split chains (at convergence Rhat=1). ## 5% 95% ## (Intercept) 1221484.49 1233769.80 ## distance_from_CBD -9970.64 -9704.66 ## distance_from_closest_private_school -8351.27 -2986.75 ## distance_from_closest_station 15465.43 17575.46 ## distance_from_closest_public_school 52477.29 65170.01 ## sigma 338928.34 342948.57 The efficacy of the model is visually represented in the charts below. The visual representations above represent the Linear Model with flat priors. This was done for all three models, flat, weak and informative priors and importantly all models converged and had R-hat values of 1 or less across all predictors. convergence of draws is below. The four models were then compared using the leave one out function (LOO) in rstanarm. This function will test the models to determine which priors applied to the model will offer the best result. It should be noted that all MCMC converged on all models as a measure of a sound model. The trace plot below visualises this. 2.3 Model Selection The model selection involves comparing the different models that have used the three different priors. .rownames elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic glm_price_weak 0.0000000 0.0000000 -543602.9 161.3315 7.916135 0.5056034 1087206 322.6630 glm_price_informative -0.0081569 0.0198058 -543602.9 161.3302 7.910412 0.5098467 1087206 322.6603 glm_price_flat -0.0263548 0.0468514 -543603.0 161.3322 7.925820 0.5089566 1087206 322.6644 The LOO information criterion (LOOIC) is used in a similar manner to the frequentist statistics measure of Akaike Information Criterion (AIC). Based on the results above it can be seen that the models all produce good results with the ‘weak’ informative prior offering the best results. This will be the model we will continue to develop. LOO Log-predictive density values to find observations that are difficult to predict (Hoff 2009; Gabry and Goodrich, n.d.). 2.3.0.1 Posterior Predictive Checking {PPC} Bayesian models with proper priors are generative models as such we need to check the priors used in the model. This is done by assessing the priors based on the marginal distribution of the data - this reflects the interplay between the prior distribution on the parameters and the likelihood (Gelman and Gelman 2013). Visually the model appears to be underestimating on the posterior predictive check in the line graph above. Further investigation with the box plot highlights that the higher values from the original data set have influenced the posteriors. The overall fit for the model is fair, the shape approximates the original Data but there is an underestimation in the predicted price based on the model variables. This is a good time to raise the issue around the interaction between priors and posterior results. Recall that Bayesian modelling methods are useful for small data sets or data sets with missing data. With a small data set the predictions will approach the priors, as the number of observations increases then the predictions will approach the posterior results. Another useful check is to consider the posterior against the prior by parameter. ## # Description of Posterior Distributions ## ## Parameter | Median | 89% CI | pd | 89% ROPE | % in ROPE | Rhat | ESS ## ------------------------------------------------------------------------------------------------------------------------------------------- ## (Intercept) | 1.228e+06 | [ 1.221e+06, 1.234e+06] | 1 | [-40906.361, 40906.361] | 0 | 1.000 | 4104.447 ## distance_from_CBD | -9837.504 | [ -9962.828, -9704.404] | 1 | [-40906.361, 40906.361] | 100 | 0.999 | 5417.531 ## distance_from_closest_private_school | -5635.805 | [ -8429.008, -3286.470] | 1 | [-40906.361, 40906.361] | 100 | 1.000 | 4400.437 ## distance_from_closest_station | 16528.637 | [ 15527.156, 17573.042] | 1 | [-40906.361, 40906.361] | 100 | 0.999 | 5234.325 ## distance_from_closest_public_school | 58703.979 | [ 52491.160, 64855.757] | 1 | [-40906.361, 40906.361] | 0 | 0.999 | 5518.889 The results above allow us to assess the centrality (median), the uncertainty (the credible interval, CI), the effect existence and effective significance - all of these values are appropriate for the model. Based on the results above from the model we can offer a 90% likelihood that the property price will be between 1.22mil and 1.23mil , the mean of 1.22mil. This seems a little unrealistic noting variance in prices between Sydney City and the outer suburbs. In order to further refine this model we will break it down by postcode to determine a more specific estimate that will be useful to future planners. After further preparing the data and running a bayesian model for each of the post codes the results were varied. Some of the postcodes only had a few observations - 3 or 4 and as such the results from the model weren’t reliable. To demonstrate this the following postcodes were taken at random to determine effectiveness of the modelling, 2095, 2099, 2147, 2170, 2231. These postcodes are generally in the likley development areas for the Greater Sydney Region Commission. Postcode 2095. ## [[1]] ## stan_glm ## family: gaussian [identity] ## formula: price ~ distance_from_CBD + distance_from_closest_private_school + ## distance_from_closest_station + distance_from_closest_public_school ## observations: 7 ## predictors: 5 ## ------ ## Median MAD_SD ## (Intercept) -11171169.3 6933674.7 ## distance_from_CBD 779759.2 1381131.9 ## distance_from_closest_private_school 1994519.4 1326481.6 ## distance_from_closest_station 403926.9 1828820.8 ## distance_from_closest_public_school -352967.2 725578.7 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 317287.0 117729.3 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg Postcode 2099. ## [[1]] ## stan_glm ## family: gaussian [identity] ## formula: price ~ distance_from_CBD + distance_from_closest_private_school + ## distance_from_closest_station + distance_from_closest_public_school ## observations: 100 ## predictors: 5 ## ------ ## Median MAD_SD ## (Intercept) 4018047.8 1182902.2 ## distance_from_CBD -164709.8 91147.7 ## distance_from_closest_private_school 506864.7 144458.7 ## distance_from_closest_station -38934.9 82940.2 ## distance_from_closest_public_school -275234.2 153160.5 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 399029.9 28941.3 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg Postcode 2147 ## [[1]] ## stan_glm ## family: gaussian [identity] ## formula: price ~ distance_from_CBD + distance_from_closest_private_school + ## distance_from_closest_station + distance_from_closest_public_school ## observations: 186 ## predictors: 5 ## ------ ## Median MAD_SD ## (Intercept) 695045.7 368677.7 ## distance_from_CBD -6177.9 13151.0 ## distance_from_closest_private_school 71768.7 23385.2 ## distance_from_closest_station 75017.0 22210.5 ## distance_from_closest_public_school 95854.2 46234.3 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 124645.2 6587.0 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg Postcode 2170 ## [[1]] ## stan_glm ## family: gaussian [identity] ## formula: price ~ distance_from_CBD + distance_from_closest_private_school + ## distance_from_closest_station + distance_from_closest_public_school ## observations: 217 ## predictors: 5 ## ------ ## Median MAD_SD ## (Intercept) 1019976.5 106301.9 ## distance_from_CBD -14015.8 3709.8 ## distance_from_closest_private_school 77945.4 26575.7 ## distance_from_closest_station 43569.2 15068.5 ## distance_from_closest_public_school 14759.6 37370.4 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 152965.8 7290.8 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg Postcode 2231 ## [[1]] ## stan_glm ## family: gaussian [identity] ## formula: price ~ distance_from_CBD + distance_from_closest_private_school + ## distance_from_closest_station + distance_from_closest_public_school ## observations: 9 ## predictors: 5 ## ------ ## Median MAD_SD ## (Intercept) 21937322.8 15746140.3 ## distance_from_CBD -1155945.0 1340572.3 ## distance_from_closest_private_school 47147.9 1159968.9 ## distance_from_closest_station -364705.1 392683.5 ## distance_from_closest_public_school 63329.3 518687.5 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 200359.7 61232.0 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg The varied medians in addition to the significantly different standard deviations across the models demonstrate strong localised effects in each of the postcodes, this is to be expected as there is both differences in the number of observations and the training data for each of the postcodes varies somewhat. It should be noted that the influences of the distances to services was very different in each of the postcodes selected and this likely affected the modelling parameters. ** Note ** I was unable to run all of the nested models for the complete data set due to computing power and errors in the Data, some postcodes only had a single observation. Biblography "],
["findings-and-reflection.html", "3 Findings and Reflection 3.1 The Bayesian GLM 3.2 The GLM compared with the Bayesian Model 3.3 The Postcode specific model 3.4 Reflections", " 3 Findings and Reflection The findings for the paper can be broken into three areas, the performance of the Bayesian GLM developed, the comparison of the GLM with the Bayes GLM and the Bayes model that was developed across the postcodes for the region. 3.1 The Bayesian GLM The performance of the Baysian GLM is best summarised in the table below. X1 n_eff Rhat mean mcse sd 2.5% 25% 50% 75% 97.5% (Intercept) 4104 1 1227639.7 59.9 3834.6 1220139.2 1225032.0 1227594.3 1230336.4 1235096.3 distance_from_CBD 5418 1 -9837.3 1.1 80.7 -9998.1 -9891.0 -9837.5 -9784.6 -9679.1 distance_from_closest_private_school 4400 1 -5656.2 24.2 1604.7 -8773.6 -6708.3 -5635.8 -4581.7 -2469.6 distance_from_closest_station 5234 1 16533.6 9.0 651.7 15234.5 16100.7 16528.6 16974.4 17797.4 distance_from_closest_public_school 5519 1 58758.6 51.2 3804.3 51246.0 56222.1 58704.0 61289.5 66318.7 sigma 2644 1 340961.7 23.8 1221.2 338567.7 340115.7 340974.0 341772.9 343367.3 mean_PPD 2289 1 939729.2 51.4 2460.0 934876.8 938113.9 939744.0 941412.6 944568.4 log-posterior 1987 1 -543619.9 0.0 1.8 -543624.2 -543620.8 -543619.5 -543618.6 -543617.5 While the R-hat values were all sound and the chains all converged as expected the actual predictive value of the model was lacking when trying to answer the research question. The standard deviation it offers was somewhat smaller than that for the GLM model using the same parameters 3.2 The GLM compared with the Bayesian Model The results from the Bayesian model offer a credibility interval rather than a confidence interval. The credible interval (95%) offered by the Bayesian GLM was between $1220139.20 and 1235096.30 with a SD of 3834.60. The original linear model demonstrated similar figures. What the Baysian model does allow us to do is offer a different way to interpret the results; by using the credibility interval as opposed to the confidence interval. 3.3 The Postcode specific model As was noted at the end of part 2, the processing power to run a complex model such as this was significant. In order to ensure the model was run only 10% of the train data was used which no doubt had an affect on the quality of the results. Of interest though even with a limited comparison between the models it is evident that the geographic specifics within the region will impact on property prices. 3.4 Reflections Priors, Priors and more Priors… The evidence required to set informative priors is troublesome. This is where the art comes into play as opposed to the science, although the idea is that they are set based on expert Knowldge. The original linear model developed in conjunction with summary statistics offered some insights into how the models might perform in a relatively simple modelling scenario. If the model was expanded to include house features, location features, population considerations and financial indicators (to name a few) then the setting of the priors would be challenging. The default settings on the rstanarm package seems to work reasonably well and as has been demonstrated in this paper they will likely outperform the experts. "],
["conclusions.html", "4 Conclusions 4.1 Are the results reliable? 4.2 Can the model be refined and how?", " 4 Conclusions Property prices in Sydney are an incredibly complex issue to say the least. There are several influences on them as part of a global economy. The modelling performed during this study has demonstrated that Bayes inferences developed from large data sets will tend towards the posterior results and the power of bayes can be lost somewhat. Bayes methods offer the greatest utility when they are applied to smaller Data sets or Data Sets with missing values. The ability to draw on the prior knowledge in small Data sets is invaluable when making predictions around future values. 4.1 Are the results reliable? This model has enabled an explanation in a very complex scenario. The ability to refer to the likelihood of price fluctuations as a product of distance from services is something that we were not able to do using the frequentist methods. The methods that probability of influence is described with the Bayesian Confidence Intervals offer a more subjective way to deal with modelling scenarios. The initial results from the general model that considered access to services and didn’t offer any breakdown by postcode failed to understand the details and influences that are apparent in the property markets. How the original model would perform when broken down into postcodes is a future body of work. By running the model across the smaller ‘data sets’ in each postcode the strength of the Bayesian modelling began to emerge. The smaller data sets in each post code effectively offer the opportunity to maximise the predictive possibilities. It is likley that setting the priors acurately when using small data sets would offer much greater utility. 4.2 Can the model be refined and how? The model, while being focused on access to services and how this will affect property prices doesn’t account for a multitude of other influences on property prices. Variables such as interest rates, immigration rates, overall supply and demand, vacancy rates for rental properties, the individual property features, the list is exhaustive. As a start thought to understand the ‘type’ of property in each of the postcodes then determine the access to services, including busses has the potential to yeild a more reliable model which could offer greater insight for planners and financial institutions as it relates to the types of properties that should be forecast and zoned as part of the master planning. "],
["annex-1.html", "Annex 1", " Annex 1 The results from the adjusted GLM from the original work is below. .metric .estimator .estimate rmse standard 3.409446e+05 rsq standard 3.077495e-01 mae standard 2.671258e+05 term estimate std.error statistic p.value (Intercept) 1228524.471 3777.94137 325.183572 0.0000000 distance_from_CBD -9759.984 79.33474 -123.022827 0.0000000 distance_from_closest_station 16113.608 644.60351 24.997704 0.0000000 distance_from_closest_public_school 56845.556 3760.19042 15.117733 0.0000000 distance_from_closest_private_school -5909.948 1573.45464 -3.756033 0.0001729 A Graph of comparison between the testing data and the training data is below. "],
["biblography.html", "Biblography", " Biblography "]
]
